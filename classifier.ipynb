{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This notebook will create a natural language processor that is able \n",
    "### to take in task titles and predict the category that they belong to (Work, Home, Shopping)\n",
    "\n",
    "\n",
    "## Hosted at https://gitlab.com/Task_Management_CompSci/task_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "!pip install -q pandas tensorflow numpy tensorflow_hub sklearn # quietly install anything we need.\n",
    "\n",
    "import pandas as pd # use pandas package for file processing. (Reading from todos.csv)\n",
    "import tensorflow as tf # use tensorflow to create the model itself.\n",
    "import numpy as np # use numpy for calculations and array handling \n",
    "import tensorflow_hub as hub # use tensorflow hub to get hold of pretrained model\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variable data_file to string with name of file with dataset store.\n",
    "data_file = \"todos.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do the shopping</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go to work</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do the washing</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Get a haircut</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Print agendas</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              task category\n",
       "0  Do the shopping        S\n",
       "1       Go to work        W\n",
       "2   Do the washing        H\n",
       "3    Get a haircut        S\n",
       "4    Print agendas        W"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_file) # create a dataframe from the dataset.\n",
    "df.head() \n",
    "# check that the dataframe has been generated properly by checking top 5 datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_size = int(len(df) * .8)\n",
    "\n",
    "train_descriptions = df.task[:train_size].astype(\"str\")\n",
    "\n",
    "train_categories = df.category[:train_size]\n",
    "\n",
    "test_descriptions = df.task[train_size:].astype(\"str\")\n",
    "test_categories = df.category[train_size:]\n",
    "# Execute the test train split with 4:1 ratio (80% train, 20% test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# import sklearn preprocessing to create one-hot vectors for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = MultiLabelBinarizer()\n",
    "encoder.fit_transform(train_categories)\n",
    "train_encoded = encoder.transform(train_categories)\n",
    "test_encoded = encoder.transform(test_categories)\n",
    "num_classes = len(encoder.classes_)\n",
    "# Create one hot vectors from training and test labels.\n",
    "# Therefore, instead of a title being classified as 'S' (for shopping), it is classified as [0, 1, 0]\n",
    "\n",
    "num_classes\n",
    "# check that encoding worked by verifying that there are three values in generated vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label_head = tf.contrib.estimator.multi_label_head(\n",
    "    num_classes,\n",
    "    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Create a placeholder model to classify tasks. \n",
    "# Model will output a one-hot of length 3 after being given an input \n",
    "# of unknown size \n",
    "# (perfect for text, as size is variable and cannot be modelled by fixed no neurons in Dense NN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_embeddings = hub.text_embedding_column(\"task\", module_spec=\"http://tfhub.dev/google/universal-sentence-encoder/2\", trainable=False)\n",
    "\n",
    "# Get hold of a pretrained model, which is to be transfered onto the problem at hand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = { # Only feature of datapoints is the title of the example. \n",
    "  \"task\": np.array(train_descriptions).astype(np.str) # store this title in a dictionary.\n",
    "}  \n",
    "labels = np.array(train_encoded).astype(np.int32) # store labels as a numpy array.\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(features, labels, shuffle=True, batch_size=1, num_epochs=25)\n",
    "# Above, create a model to feed inputs into the network, batch size of 1 and over 25 epochs. \n",
    "# Shuffle to ensure each epoch is in different order.\n",
    "estimator = tf.contrib.estimator.DNNEstimator( \n",
    "    # Implement the model by creating a dense network for estimation.\n",
    "    head=multi_label_head,\n",
    "    hidden_units=[64,10],\n",
    "    feature_columns=[headline_embeddings], model_dir='models/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.estimator.python.estimator.dnn.DNNEstimator at 0x1c3f108860>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=train_input_fn) # train the classifier on test and train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.9999999,\n",
       " 'auc_precision_recall': 0.9999998,\n",
       " 'average_loss': 0.021712666,\n",
       " 'loss': 0.021712666,\n",
       " 'global_step': 1425}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn({\"task\": np.array(test_descriptions).astype(np.str)}, test_encoded.astype(np.int32), shuffle=False)\n",
    "estimator.evaluate(input_fn=eval_input_fn)\n",
    "# Evaluate the model by testing with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['H', 'S', 'W'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\"Computer Science homework\"]\n",
    "# Feeding in example of 'Computer Science homework', expect this classified as work.\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn({\"task\": np.array(data).astype(np.str)}, shuffle=False)\n",
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = estimator.predict(predict_input_fn) # predict the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results\n",
    "category = [\"home\", \"shopping\", \"work\"] # get the result of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work\n"
     ]
    }
   ],
   "source": [
    "for i in results:\n",
    "    print(category[np.argmax(i[\"probabilities\"])]) # show result in text as eithe work, shopping or home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should predict that the data 'computer science homework' should be categorised as work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
